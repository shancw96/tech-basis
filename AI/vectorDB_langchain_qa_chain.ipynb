{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugarforever/WTFAcademyChatBot/blob/main/WTFAcademyChatBotChroma.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "该Python notebook演示了如何利用langchain的QA chain，结合Chroma来实现博客的语义化搜索。\n",
        "使用时，在本地创建`.env`，并如`.env.example`所示，设置有效的OpenAI API Key即可。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nifwi9FrKb3g"
      },
      "outputs": [],
      "source": [
        "%pip install openai\n",
        "%pip install chromadb\n",
        "%pip install langchain\n",
        "%pip install unstructured"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 文档预处理"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xgbUBve0LuN"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import DirectoryLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-1itVpTY8Gz"
      },
      "outputs": [],
      "source": [
        "def load_all_courses(dir):\n",
        "  loader = DirectoryLoader(dir, glob = \"**/*.md\")\n",
        "  docs = loader.load()\n",
        "\n",
        "  return docs\n",
        "\n",
        "docs = load_all_courses(\"/Users/wushangcheng/Desktop/Archive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33zAThYjY9gA",
        "outputId": "bc6d338b-82e3-461f-be11-04b4f44af8fb"
      },
      "outputs": [],
      "source": [
        "print (f'You have {len(docs)} document(s) in your data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziV20FzmZpm1"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "split_docs = text_splitter.split_documents(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlDqqN_6Z08T",
        "outputId": "c0f4d8f4-2840-41cf-c3fd-dd8da6b9a9fa"
      },
      "outputs": [],
      "source": [
        "print (f'Now you have {len(split_docs)} documents')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Embedding - Openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IOlsXpbaIAw"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "import os\n",
        "\n",
        "OPENAI_API_KEY = \"123\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bE-KtYTCgkLw"
      },
      "outputs": [],
      "source": [
        "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGdpt9LygkLy"
      },
      "outputs": [],
      "source": [
        "persist_directory = 'blog_vector_storage'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "这步操作属于初始化操作，将文档转换为向量并存储，后续可以直接使用。（只需要执行一次）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mQJJ8HRaf0I",
        "outputId": "d9343337-2df2-49dd-84d3-ac354ee65b7c"
      },
      "outputs": [],
      "source": [
        "# vectorstore = Chroma.from_documents(split_docs, embeddings, persist_directory=persist_directory)\n",
        "# vectorstore.persist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DtgsLeOgkLz",
        "outputId": "12a51bb9-9741-4682-9ebd-c6beea455fff"
      },
      "outputs": [],
      "source": [
        "# Load the vectorstore from disk\n",
        "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embeddings)\n",
        "\n",
        "query = \"docker 如何创建一个mysql容器？\"\n",
        "docs = vectordb.similarity_search(query)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "通过Embedding加载关联上下文完毕后，开始进行QA。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBAx1_X-beQp"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8hds-zybhfc"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n",
        "chain = load_qa_chain(llm, chain_type=\"map_reduce\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdF03LqphOQY",
        "outputId": "bc596972-7e39-479a-a921-5b17204f4b7f"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "split_docs = text_splitter.split_documents(docs)\n",
        "\n",
        "chain.run(input_documents=split_docs, question=query)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
